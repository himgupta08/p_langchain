{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain\n",
    "LangChain is a python based framework to help build LLM-powered applications through the concepts of prompt templates, chains and agents. It is an open-source project [GitHub repository] (https://github.com/hwchase17/langchain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "import api_keys as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = api.open_ai_api_key\n",
    "# api keys are saved locally\n",
    "\n",
    "# your account will be frontloaded with $120 per month for the token usage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Get answers from the Open AI directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. China - 1.4 billion\n",
      "2. India - 1.3 billion\n",
      "3. United States - 329 million\n",
      "4. Indonesia - 269 million\n",
      "5. Brazil - 211 million\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0)\n",
    "# temp can range from 0 to 2 which means a range of 'deterministic' output to 'non-deterministic' output.\n",
    "# deterministic means results will not differ at all from 1 prompt\n",
    "\n",
    "text = \"name the top 5 countries with their highest population \"\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The latest month a chat GPT model has been trained on is April 2021. The version you are talking to is GPT-3.\n"
     ]
    }
   ],
   "source": [
    "print(llm(\"what is the latest month chat gpt model trained on? what version am I talking to?\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Using prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. United States - $21.44 trillion\n",
      "2. China - $14.14 trillion\n",
      "3. Japan - $5.15 trillion\n",
      "4. Germany - $4.00 trillion\n",
      "5. India - $2.94 trillion\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"criteria\"],\n",
    "    template=\"name the top 5 countries with their highest {criteria} \"\n",
    ")\n",
    "\n",
    "print(llm(prompt.format(criteria=\"economy\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Russia (17,098,242 km2)\n",
      "2. Canada (9,984,670 km2)\n",
      "3. China (9,706,961 km2)\n",
      "4. United States (9,372,610 km2)\n",
      "5. Brazil (8,515,767 km2)\n"
     ]
    }
   ],
   "source": [
    "print(llm(prompt.format(criteria=\"area\")))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Chains: Combine LLMs and prompts\n",
    "\n",
    "Chains allow us to combine multiple components together to create a single, coherent application. More complex chains can be created by combining multiple chains or componenets together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. United States - $21.44 trillion\n",
      "2. China - $14.14 trillion\n",
      "3. Japan - $5.15 trillion\n",
      "4. Germany - $4.00 trillion\n",
      "5. India - $2.94 trillion\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "print(chain.run(\"economy\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Search Google and compare results\n",
    "\n",
    "Agents use an LLM to determine which actions to take and in what order.  \n",
    "One of the most common agent is Zero-shot which is based on ReACT framework (a JS library mainatained by Meta) that helps to determine which tool to use based solely on the tool's description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-search-results\n",
    "\n",
    "# serpapi is the Google search API\n",
    "os.environ[\"SERPAPI_API_KEY\"] = api.serp_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "llm = OpenAI(temperature=0)\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "\n",
    "# load agents\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", \n",
    "                         return_intermediate_steps=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out who the current leader is and their age.\n",
      "Action: Search\n",
      "Action Input: \"Current leader of USA\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mJoe Biden\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find out Joe Biden's age.\n",
      "Action: Search\n",
      "Action Input: \"Joe Biden age\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m80 years\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to sum up the digits in Joe Biden's age.\n",
      "Action: Calculator\n",
      "Action Input: 80\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 80\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Joe Biden is 80 years old and the sum of the digits in his age is 8.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Joe Biden is 80 years old and the sum of the digits in his age is 8.\n",
      "['Search', 'Search', 'Calculator']\n"
     ]
    }
   ],
   "source": [
    "# Now let's test it out!\n",
    "response = agent({\"input\":\"\"\"Who is the current leader of USA? what is their age?\n",
    "           Can you sum up the digits in his age?\"\"\"})\n",
    "\n",
    "print(response[\"output\"])\n",
    "\n",
    "print([action[0].tool for action in response[\"intermediate_steps\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Add persona to a prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting answers in simple english format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(temperature=0)\n",
    "\n",
    "template = \"You are a helpful assistant that answers to the medical questions in plain english.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "example_human = HumanMessagePromptTemplate.from_template(\"what is Allopurinol\")\n",
    "example_ai = AIMessagePromptTemplate.from_template(\"Allopurinol is a medicine used to lower levels of uric acid in your blood.\")\n",
    "human_template = \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Metformin is a medication used to treat type 2 diabetes by lowering blood sugar levels and improving insulin sensitivity.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt, example_human, example_ai, human_message_prompt]\n",
    ")\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
    "# get a chat completion from the formatted messages\n",
    "chain.run(\"what is Metformin. Explain in maximum 20 words.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting answers in complex medical terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(temperature=0)\n",
    "\n",
    "template = \"\"\"You are a medical practitioner that answers to the medical questions in difficult medical terms.\n",
    "Always respond with medical terms. Do not use plain english\"\"\"\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "example_human = HumanMessagePromptTemplate.from_template(\"what is Allopurinol\")\n",
    "example_ai = AIMessagePromptTemplate.from_template(\"Allopurinol, a xanthine oxidase inhibitor, is a urate-lowering medication that is FDA approved for managing gout, preventing tumor lysis syndrome, and preventing recurrent calcium nephrolithiasis in patients with hyperuricosuria.\")\n",
    "human_template = \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Metformin is an oral hypoglycemic medication that belongs to the biguanide class of drugs. It is used to treat type 2 diabetes mellitus by reducing glucose production in the liver, decreasing intestinal glucose absorption, and improving insulin sensitivity in peripheral tissues.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt, example_human, example_ai, human_message_prompt]\n",
    ")\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
    "# get a chat completion from the formatted messages\n",
    "chain.run(\"what is Metformin? \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
