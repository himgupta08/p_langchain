{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "import api_keys as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = api.open_ai_api_key\n",
    "# api keys are saved locally\n",
    "\n",
    "# your account will be frontloaded with $120 per month for the token usage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Get answers from the Open AI directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. China - 1.43 billion \n",
      "2. India - 1.35 billion \n",
      "3. United States - 328.2 million \n",
      "4. Indonesia -269.3 million\n",
      "5. Brazil - 211.3 million\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0.9)\n",
    "# temp can range from 0 to 2 which means a range of 'deterministic' output to 'non-deterministic' output.\n",
    "# deterministic means results will not differ at all from 1 prompt\n",
    "\n",
    "text = \"name the top 5 countries with the highest population and their population \"\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The latest history (month) chat GPT model trained on is July 2020.\n"
     ]
    }
   ],
   "source": [
    "print(llm(\"what is the latest history (month) chat gpt model trained on\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Using prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. United States - Gross Domestic Product (GDP): $20.54 trillion \n",
      "2. China - Gross Domestic Product (GDP): $13.6 trillion \n",
      "3. Japan - Gross Domestic Product (GDP): $4.92 trillion \n",
      "4. Germany - Gross Domestic Product (GDP): $4.00 trillion\n",
      "5. India - Gross Domestic Product (GDP): $2.94 trillion\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"criteria\"],\n",
    "    template=\"name the top 5 countries with the highest {criteria} and their {criteria} \"\n",
    ")\n",
    "\n",
    "print(llm(prompt.format(criteria=\"economy\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Russia - 17,098,242 km2\n",
      "2. Canada - 9,984,670 km2\n",
      "3. China - 9,706,961 km2\n",
      "4. United States - 9,372,610 km2\n",
      "5. Brazil - 8,514,877 km2\n"
     ]
    }
   ],
   "source": [
    "print(llm(prompt.format(criteria=\"area\")))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Chains: Combine LLMs and prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. United States: $21 trillion\n",
      "2. China: $14.14 trillion\n",
      "3. Japan: $5.15 trillion\n",
      "4. Germany: $4.00 trillion\n",
      "5. India: $2.94 trillion\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "print(chain.run(\"economy\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Search Google and compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-search-results\n",
    "\n",
    "# serpapi is the Google search API\n",
    "os.environ[\"SERPAPI_API_KEY\"] = api.serp_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "llm = OpenAI(temperature=0)\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "\n",
    "# load agents\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out who the current leader is and their age.\n",
      "Action: Search\n",
      "Action Input: \"Current leader of USA\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mJoe Biden\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find out Joe Biden's age\n",
      "Action: Search\n",
      "Action Input: \"Joe Biden age\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m80 years\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to sum up the digits in Joe Biden's age\n",
      "Action: Calculator\n",
      "Action Input: 8 + 0\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 8\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Joe Biden is 80 years old and the sum of the digits in his age is 8.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Joe Biden is 80 years old and the sum of the digits in his age is 8.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's test it out!\n",
    "agent.run(\"Who is the current leader of USA? What is their age? Can you sum up the digits in the age?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
